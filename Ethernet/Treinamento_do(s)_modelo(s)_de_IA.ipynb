{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from joblib import dump#, load\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.preprocessing import MinMaxScaler#, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model, Sequential#, load_model\n",
    "from keras.layers import Input, LSTM, RepeatVector, Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo o tema do seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição da SEED:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED) # Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores são números muito pequenos com muitas casas decimais, por isso é bom que o dataframe consiga representar isso também."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', '{:.20f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benign = pd.read_csv(\"pacotes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\henri\\AppData\\Local\\Temp\\ipykernel_119596\\1183154623.py:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  df_drop_packets = pd.read_csv(\"data\\Ataques\\Drop Packets 2024_6_26-18h_33m_54s\\Drop Packets.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_drop_packets = pd.read_csv(\"data\\Ataques\\Drop Packets 2024_6_26-18h_33m_54s\\Drop Packets.csv\")\n",
    "#df_malicious_spoofing_zero_payload = pd.read_csv(\"data/ataques/mensagens_maliciosas_spoofing_zero_payload.csv\")\n",
    "#df_malicious_zero_dos = pd.read_csv(\"data/ataques/mensagens_maliciosas_zero_dos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rel Time</th>\n",
       "      <th>Length</th>\n",
       "      <th>Data_1</th>\n",
       "      <th>Data_2</th>\n",
       "      <th>Data_3</th>\n",
       "      <th>Data_4</th>\n",
       "      <th>Data_5</th>\n",
       "      <th>Data_6</th>\n",
       "      <th>Data_7</th>\n",
       "      <th>Data_8</th>\n",
       "      <th>...</th>\n",
       "      <th>Data_44</th>\n",
       "      <th>Data_45</th>\n",
       "      <th>Data_46</th>\n",
       "      <th>Data_47</th>\n",
       "      <th>Data_48</th>\n",
       "      <th>Data_49</th>\n",
       "      <th>Data_50</th>\n",
       "      <th>Data_51</th>\n",
       "      <th>Data_52</th>\n",
       "      <th>Data_53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000000000000000000</td>\n",
       "      <td>170</td>\n",
       "      <td>37159</td>\n",
       "      <td>37159</td>\n",
       "      <td>36947</td>\n",
       "      <td>35264</td>\n",
       "      <td>36740</td>\n",
       "      <td>33886</td>\n",
       "      <td>36538</td>\n",
       "      <td>33050</td>\n",
       "      <td>...</td>\n",
       "      <td>19947</td>\n",
       "      <td>33675</td>\n",
       "      <td>23169</td>\n",
       "      <td>33577</td>\n",
       "      <td>25995</td>\n",
       "      <td>33486</td>\n",
       "      <td>28377</td>\n",
       "      <td>33399</td>\n",
       "      <td>30272</td>\n",
       "      <td>33318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00066600000000000003</td>\n",
       "      <td>170</td>\n",
       "      <td>32949</td>\n",
       "      <td>28377</td>\n",
       "      <td>32907</td>\n",
       "      <td>25995</td>\n",
       "      <td>32871</td>\n",
       "      <td>23169</td>\n",
       "      <td>32840</td>\n",
       "      <td>19947</td>\n",
       "      <td>...</td>\n",
       "      <td>33050</td>\n",
       "      <td>33318</td>\n",
       "      <td>33886</td>\n",
       "      <td>33399</td>\n",
       "      <td>35264</td>\n",
       "      <td>33486</td>\n",
       "      <td>37159</td>\n",
       "      <td>33577</td>\n",
       "      <td>39541</td>\n",
       "      <td>33675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00066699999999999995</td>\n",
       "      <td>170</td>\n",
       "      <td>34373</td>\n",
       "      <td>0</td>\n",
       "      <td>34508</td>\n",
       "      <td>4276</td>\n",
       "      <td>34649</td>\n",
       "      <td>8480</td>\n",
       "      <td>34795</td>\n",
       "      <td>12539</td>\n",
       "      <td>...</td>\n",
       "      <td>12539</td>\n",
       "      <td>38532</td>\n",
       "      <td>8480</td>\n",
       "      <td>38778</td>\n",
       "      <td>4276</td>\n",
       "      <td>39027</td>\n",
       "      <td>0</td>\n",
       "      <td>39282</td>\n",
       "      <td>61260</td>\n",
       "      <td>39541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00066699999999999995</td>\n",
       "      <td>170</td>\n",
       "      <td>41186</td>\n",
       "      <td>37159</td>\n",
       "      <td>41475</td>\n",
       "      <td>35264</td>\n",
       "      <td>41768</td>\n",
       "      <td>33886</td>\n",
       "      <td>42065</td>\n",
       "      <td>33050</td>\n",
       "      <td>...</td>\n",
       "      <td>19947</td>\n",
       "      <td>48416</td>\n",
       "      <td>23169</td>\n",
       "      <td>48783</td>\n",
       "      <td>25995</td>\n",
       "      <td>49153</td>\n",
       "      <td>28377</td>\n",
       "      <td>49526</td>\n",
       "      <td>30272</td>\n",
       "      <td>49901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00066600000000000003</td>\n",
       "      <td>170</td>\n",
       "      <td>52209</td>\n",
       "      <td>28377</td>\n",
       "      <td>52602</td>\n",
       "      <td>25995</td>\n",
       "      <td>52997</td>\n",
       "      <td>23169</td>\n",
       "      <td>53394</td>\n",
       "      <td>19947</td>\n",
       "      <td>...</td>\n",
       "      <td>33050</td>\n",
       "      <td>61260</td>\n",
       "      <td>33886</td>\n",
       "      <td>61685</td>\n",
       "      <td>35264</td>\n",
       "      <td>62111</td>\n",
       "      <td>37159</td>\n",
       "      <td>62538</td>\n",
       "      <td>39541</td>\n",
       "      <td>62966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899836</th>\n",
       "      <td>0.00066600000000000003</td>\n",
       "      <td>170</td>\n",
       "      <td>32949</td>\n",
       "      <td>28377</td>\n",
       "      <td>32907</td>\n",
       "      <td>25995</td>\n",
       "      <td>32871</td>\n",
       "      <td>23169</td>\n",
       "      <td>32840</td>\n",
       "      <td>19947</td>\n",
       "      <td>...</td>\n",
       "      <td>33050</td>\n",
       "      <td>33318</td>\n",
       "      <td>33886</td>\n",
       "      <td>33399</td>\n",
       "      <td>35264</td>\n",
       "      <td>33486</td>\n",
       "      <td>37159</td>\n",
       "      <td>33577</td>\n",
       "      <td>39541</td>\n",
       "      <td>33675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899837</th>\n",
       "      <td>0.00066699999999999995</td>\n",
       "      <td>170</td>\n",
       "      <td>34373</td>\n",
       "      <td>0</td>\n",
       "      <td>34508</td>\n",
       "      <td>4276</td>\n",
       "      <td>34649</td>\n",
       "      <td>8480</td>\n",
       "      <td>34795</td>\n",
       "      <td>12539</td>\n",
       "      <td>...</td>\n",
       "      <td>12539</td>\n",
       "      <td>38532</td>\n",
       "      <td>8480</td>\n",
       "      <td>38778</td>\n",
       "      <td>4276</td>\n",
       "      <td>39027</td>\n",
       "      <td>0</td>\n",
       "      <td>39282</td>\n",
       "      <td>61260</td>\n",
       "      <td>39541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899838</th>\n",
       "      <td>0.00066699999999999995</td>\n",
       "      <td>170</td>\n",
       "      <td>41186</td>\n",
       "      <td>37159</td>\n",
       "      <td>41475</td>\n",
       "      <td>35264</td>\n",
       "      <td>41768</td>\n",
       "      <td>33886</td>\n",
       "      <td>42065</td>\n",
       "      <td>33050</td>\n",
       "      <td>...</td>\n",
       "      <td>19947</td>\n",
       "      <td>48416</td>\n",
       "      <td>23169</td>\n",
       "      <td>48783</td>\n",
       "      <td>25995</td>\n",
       "      <td>49153</td>\n",
       "      <td>28377</td>\n",
       "      <td>49526</td>\n",
       "      <td>30272</td>\n",
       "      <td>49901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899839</th>\n",
       "      <td>0.00066699999999999995</td>\n",
       "      <td>170</td>\n",
       "      <td>52209</td>\n",
       "      <td>28377</td>\n",
       "      <td>52602</td>\n",
       "      <td>25995</td>\n",
       "      <td>52997</td>\n",
       "      <td>23169</td>\n",
       "      <td>53394</td>\n",
       "      <td>19947</td>\n",
       "      <td>...</td>\n",
       "      <td>33050</td>\n",
       "      <td>61260</td>\n",
       "      <td>33886</td>\n",
       "      <td>61685</td>\n",
       "      <td>35264</td>\n",
       "      <td>62111</td>\n",
       "      <td>37159</td>\n",
       "      <td>62538</td>\n",
       "      <td>39541</td>\n",
       "      <td>62966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899840</th>\n",
       "      <td>0.00066600000000000003</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>428</td>\n",
       "      <td>4276</td>\n",
       "      <td>857</td>\n",
       "      <td>8480</td>\n",
       "      <td>1286</td>\n",
       "      <td>12539</td>\n",
       "      <td>...</td>\n",
       "      <td>12539</td>\n",
       "      <td>9306</td>\n",
       "      <td>8480</td>\n",
       "      <td>9716</td>\n",
       "      <td>4276</td>\n",
       "      <td>10125</td>\n",
       "      <td>0</td>\n",
       "      <td>10532</td>\n",
       "      <td>61260</td>\n",
       "      <td>10937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>899841 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Rel Time  Length  Data_1  Data_2  Data_3  Data_4  Data_5  \\\n",
       "0      0.00000000000000000000     170   37159   37159   36947   35264   36740   \n",
       "1      0.00066600000000000003     170   32949   28377   32907   25995   32871   \n",
       "2      0.00066699999999999995     170   34373       0   34508    4276   34649   \n",
       "3      0.00066699999999999995     170   41186   37159   41475   35264   41768   \n",
       "4      0.00066600000000000003     170   52209   28377   52602   25995   52997   \n",
       "...                       ...     ...     ...     ...     ...     ...     ...   \n",
       "899836 0.00066600000000000003     170   32949   28377   32907   25995   32871   \n",
       "899837 0.00066699999999999995     170   34373       0   34508    4276   34649   \n",
       "899838 0.00066699999999999995     170   41186   37159   41475   35264   41768   \n",
       "899839 0.00066699999999999995     170   52209   28377   52602   25995   52997   \n",
       "899840 0.00066600000000000003     170       0       0     428    4276     857   \n",
       "\n",
       "        Data_6  Data_7  Data_8  ...  Data_44  Data_45  Data_46  Data_47  \\\n",
       "0        33886   36538   33050  ...    19947    33675    23169    33577   \n",
       "1        23169   32840   19947  ...    33050    33318    33886    33399   \n",
       "2         8480   34795   12539  ...    12539    38532     8480    38778   \n",
       "3        33886   42065   33050  ...    19947    48416    23169    48783   \n",
       "4        23169   53394   19947  ...    33050    61260    33886    61685   \n",
       "...        ...     ...     ...  ...      ...      ...      ...      ...   \n",
       "899836   23169   32840   19947  ...    33050    33318    33886    33399   \n",
       "899837    8480   34795   12539  ...    12539    38532     8480    38778   \n",
       "899838   33886   42065   33050  ...    19947    48416    23169    48783   \n",
       "899839   23169   53394   19947  ...    33050    61260    33886    61685   \n",
       "899840    8480    1286   12539  ...    12539     9306     8480     9716   \n",
       "\n",
       "        Data_48  Data_49  Data_50  Data_51  Data_52  Data_53  \n",
       "0         25995    33486    28377    33399    30272    33318  \n",
       "1         35264    33486    37159    33577    39541    33675  \n",
       "2          4276    39027        0    39282    61260    39541  \n",
       "3         25995    49153    28377    49526    30272    49901  \n",
       "4         35264    62111    37159    62538    39541    62966  \n",
       "...         ...      ...      ...      ...      ...      ...  \n",
       "899836    35264    33486    37159    33577    39541    33675  \n",
       "899837     4276    39027        0    39282    61260    39541  \n",
       "899838    25995    49153    28377    49526    30272    49901  \n",
       "899839    35264    62111    37159    62538    39541    62966  \n",
       "899840     4276    10125        0    10532    61260    10937  \n",
       "\n",
       "[899841 rows x 55 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_malicious_random_dos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_malicious_spoofing_zero_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_malicious_zero_dos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipualação da quantidade/proporção dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL!!!\n",
    "len_min = min(len(df_benign),len(df_malicious_random_dos),len(df_malicious_spoofing_zero_payload),len(df_malicious_zero_dos))\n",
    "NUM_OF_ATTACKS = 3\n",
    "\n",
    "#len_min = int(len_min / 40)\n",
    "\n",
    "#df_benign = df_benign.head(len_min * NUM_OF_ATTACKS)\n",
    "df_malicious_random_dos = df_malicious_random_dos.head(len_min)\n",
    "df_malicious_spoofing_zero_payload = df_malicious_spoofing_zero_payload.head(len_min)\n",
    "df_malicious_zero_dos = df_malicious_zero_dos.head(len_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del len_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratando dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação e uso do scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(df_benign)\n",
    "\n",
    "df_benign_scaled = pd.DataFrame(scaler.transform(df_benign), columns=df_benign.columns, index=df_benign.index)\n",
    "df_malicious_random_dos_scaled = pd.DataFrame(scaler.transform(df_malicious_random_dos), columns=df_malicious_random_dos.columns, index=df_malicious_random_dos.index)\n",
    "df_malicious_spoofing_zero_payload_scaled = pd.DataFrame(scaler.transform(df_malicious_spoofing_zero_payload), columns=df_malicious_spoofing_zero_payload.columns, index=df_malicious_spoofing_zero_payload.index)\n",
    "df_malicious_zero_dos_scaled = pd.DataFrame(scaler.transform(df_malicious_zero_dos), columns=df_malicious_zero_dos.columns, index=df_malicious_zero_dos.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_benign\n",
    "del df_malicious_random_dos\n",
    "del df_malicious_spoofing_zero_payload\n",
    "del df_malicious_zero_dos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benign_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação de Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_labels_benign = [1] * len(df_benign_scaled)\n",
    "list_labels_random_dos = [-1] * len(df_malicious_random_dos_scaled)\n",
    "list_labels_spoofing_zero_payload = [-1] * len(df_malicious_spoofing_zero_payload_scaled)\n",
    "list_labels_zero_dos = [-1] * len(df_malicious_zero_dos_scaled)\n",
    "\n",
    "classifier_type = \"bc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação de Janelas Temporais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de Janelas Deslizantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação da função de divisão dos dados em janelas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_slicing_windows(data, labels, time_step=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data) - time_step):\n",
    "        a = data[i:(i + time_step)]\n",
    "        X.append(a)\n",
    "        Y.append(labels[i + time_step])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição do tamanho da janela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação das janelas deslizantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_windows, benign_labels = create_slicing_windows(df_benign_scaled, list_labels_benign, WINDOW_SIZE)\n",
    "del df_benign_scaled, list_labels_benign\n",
    "\n",
    "malicious_random_dos_windows, malicious_random_dos_labels = create_slicing_windows(df_malicious_random_dos_scaled, list_labels_random_dos, WINDOW_SIZE)\n",
    "del df_malicious_random_dos_scaled, list_labels_random_dos\n",
    "\n",
    "malicious_spoofing_zero_payload_windows, malicious_spoofing_zero_payload_labels = create_slicing_windows(df_malicious_spoofing_zero_payload_scaled, list_labels_spoofing_zero_payload, WINDOW_SIZE)\n",
    "del df_malicious_spoofing_zero_payload_scaled, list_labels_spoofing_zero_payload\n",
    "\n",
    "malicious_zero_dos_windows, malicious_zero_dos_labels = create_slicing_windows(df_malicious_zero_dos_scaled, list_labels_zero_dos, WINDOW_SIZE)\n",
    "del df_malicious_zero_dos_scaled, list_labels_zero_dos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(benign_windows), len(benign_windows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividindo dados em Treino, Validação e Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade de dados benignos dividido pelo total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(benign_windows) / (len(benign_windows) + len(malicious_random_dos_windows) + len(malicious_spoofing_zero_payload_windows) + len(malicious_zero_dos_windows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenação das janelas, em ordem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack((benign_windows, malicious_random_dos_windows, malicious_spoofing_zero_payload_windows, malicious_zero_dos_windows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_malicious = np.vstack((malicious_random_dos_windows, malicious_spoofing_zero_payload_windows, malicious_zero_dos_windows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = np.hstack((benign_labels, malicious_random_dos_labels, malicious_spoofing_zero_payload_labels, malicious_zero_dos_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_malicious_labels = np.hstack((malicious_random_dos_labels, malicious_spoofing_zero_payload_labels, malicious_zero_dos_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del malicious_random_dos_windows\n",
    "del malicious_spoofing_zero_payload_windows\n",
    "del malicious_zero_dos_windows\n",
    "del malicious_random_dos_labels\n",
    "del malicious_spoofing_zero_payload_labels\n",
    "del malicious_zero_dos_labels\n",
    "del benign_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão em treino, validação e teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abordagem supervisionada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_test_data, train_labels, val_test_labels = train_test_split(data, data_labels, test_size=0.25, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data, test_data, val_labels, test_labels = train_test_split(val_test_data, val_test_labels, test_size=0.5, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data, data_labels\n",
    "del val_test_data, val_test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abordagem não-supervisionada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2 = benign_windows[:int((len(benign_windows) // 1.05))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_2 = np.vstack((data_malicious, benign_windows[int((len(benign_windows) // 1.05)):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malicious_proportion = len(data_malicious) / (len(data_malicious) + len(benign_windows[int((len(benign_windows) // 1.05)):]))\n",
    "malicious_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_labels = [1] * int(len(benign_windows) - (len(benign_windows) // 1.05))\n",
    "\n",
    "test_data_2_labels = np.hstack((data_malicious_labels, benign_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_malicious\n",
    "del benign_windows\n",
    "del benign_labels\n",
    "del data_malicious_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape dos dados de treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM (supervisionado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variável que define se é supervisionado ou não-supervisionado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_OR_ns = \"s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade de features, para o modelo lidar com as entradas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_COUNT = train_data.shape[2] # Número de features dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construção do modelo LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construindo o modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='tanh', input_shape=(WINDOW_SIZE, FEATURES_COUNT)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, kernel_regularizer=l2(0.0000001)))\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.004), loss='mse')\n",
    "#model.compile(optimizer=\"adam\", loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição da paciência:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuração do early stop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição da quantidade de épocas e o tamanho do Batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32 #padrão: batch_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TREINAMENTO DO MODELO:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo\n",
    "history = model.fit(train_data, train_labels, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(val_data, val_labels), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data, train_labels\n",
    "del val_data, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando o modelo no conjunto de teste\n",
    "loss = model.evaluate(test_data, test_labels)\n",
    "print(\"Test Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model.predict(test_data)\n",
    "predicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformando as predições em uma numpy array unidimensional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_1d = np.array([predict[0] for predict in predicts])\n",
    "predicts_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(y_true, y_score):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "    plt.plot(recall, precision, marker='.')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curva Recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_curve(test_labels, predicts_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, y_score, max_fpr=1.0):\n",
    "  fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "  aucroc = roc_auc_score(y_true, y_score)\n",
    "  plt.plot(100*fpr[fpr < max_fpr], 100*tpr[fpr < max_fpr], label=f'ROC Curve (AUC = {aucroc:.4f})')\n",
    "  plt.xlim(-2,102)\n",
    "  plt.xlabel('FPR (%)')\n",
    "  plt.ylabel('TPR (%)')\n",
    "  plt.legend()\n",
    "  plt.title('ROC Curve and AUCROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curva ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(test_labels, predicts_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformando todos os valores de predições acima de 0 em 1, enquanto os outros recebem a função round(), ou seja, serão arredondados pro número inteiro mais próximo. Após isso, os números que forem iguais a 0, serão transformados em -1. É como se todo mundo igual ou menor que 0, fosse malicioso, mas 0 não é um valor malicioso de label, é mais como se fosse um threshold, então nada deve ser igual a 0. Esse problema é minimizado em classificações binárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_1d = np.where(predicts_1d > 0, 1, np.round(predicts_1d))\n",
    "predicts_1d = np.where(predicts_1d == 0, -1, predicts_1d)\n",
    "predicts_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "  cm = confusion_matrix(y_true, y_pred)\n",
    "  group_counts = [f'{value:.0f}' for value in confusion_matrix(y_true, y_pred).ravel()]\n",
    "  group_percentages = [f'{value*100:.2f}%' for value in confusion_matrix(y_true, y_pred).ravel()/np.sum(cm)]\n",
    "  labels = [f'{v1}\\n{v2}' for v1, v2 in zip(group_counts, group_percentages)]\n",
    "  labels = np.array(labels).reshape(2,2)\n",
    "  sns.heatmap(cm, annot=labels, cmap='Oranges', xticklabels=['Predicted Benign', 'Predicted Malicious'], yticklabels=['Actual Benign', 'Actual Malicious'], fmt='')\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de Confusão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_labels, predicts_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overall_metrics(y_true, y_pred):\n",
    "  tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "  acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "  tpr = tp/(tp+fn)\n",
    "  fpr = fp/(fp+tn)\n",
    "  precision = tp/(tp+fp)\n",
    "  f1 = (2*tpr*precision)/(tpr+precision)\n",
    "  return {'acc':acc,'tpr':tpr,'fpr':fpr,'precision':precision,'f1-score':f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas Gerais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_overall_metrics(test_labels, predicts_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_data, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando modelo com diferentes bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'models/model_LSTM_{s_OR_ns}_{classifier_type}_ws{WINDOW_SIZE}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'models/model_LSTM_{s_OR_ns}_{classifier_type}_ws{WINDOW_SIZE}.pkl', 'wb') as arquivo:\n",
    "    pickle.dump(model, arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model, f\"models/model_LSTM_{s_OR_ns}_{classifier_type}_ws{WINDOW_SIZE}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(scaler, f\"models/scalers/scaler_model_LSTM_{s_OR_ns}_{classifier_type}_ws{WINDOW_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del history\n",
    "del loss\n",
    "del predicts\n",
    "del predicts_1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM (não-supervisionado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo que é não-supervisionado(ns) e classificador binário(bc):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_OR_ns = \"ns\"\n",
    "classifier_type = \"bc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coletando a quantidade de features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_COUNT = train_data_2.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construção do modelo LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construindo o modelo Autoencoder LSTM\n",
    "inputs = Input(shape=(WINDOW_SIZE, FEATURES_COUNT))\n",
    "encoded = LSTM(50, activation='tanh', return_sequences=False)(inputs)  # Codificador\n",
    "decoded = RepeatVector(WINDOW_SIZE)(encoded)  # Decodificador\n",
    "decoded = LSTM(FEATURES_COUNT, return_sequences=True)(decoded)\n",
    "\n",
    "# Adicionando Dropout e Normalização em Batch\n",
    "decoded = Dropout(0.1)(decoded)\n",
    "decoded = BatchNormalization()(decoded)\n",
    "\n",
    "# Camada de saída\n",
    "outputs = Dense(FEATURES_COUNT, kernel_regularizer=l2(0.0000001))(decoded)\n",
    "\n",
    "# Compilando o modelo\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer=Adam(learning_rate=0.004), loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo a paciência:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurando o early stopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo a quantidade de épocas e o tamanho do Batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32 #padrão: batch_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TREINAMENTO DO MODELO:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data_2, train_data_2, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predições e Classificações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model.predict(test_data_2)\n",
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_error(original_data, predicted_data, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Função para classificar as amostras como benignas (1) ou malignas (-1) com base no erro de reconstrução.\n",
    "\n",
    "    Parâmetros:\n",
    "        original_data (numpy.array): Os dados originais.\n",
    "        predicted_data (numpy.array): As previsões geradas pelo modelo autoencoder.\n",
    "        threshold (float): O limiar de decisão para classificar as amostras.\n",
    "\n",
    "    Retorna:\n",
    "        numpy.array: Um array de classificação binária para cada amostra.\n",
    "    \"\"\"\n",
    "    # Calcula o erro de reconstrução (MSE) para cada amostra\n",
    "    reconstruction_errors = np.mean(np.square(original_data - predicted_data), axis=(1, 2))\n",
    "\n",
    "    # Classifica as amostras com base no limiar\n",
    "    classifications = np.where(reconstruction_errors < threshold, 1, -1)\n",
    "\n",
    "    #del reconstruction_errors\n",
    "\n",
    "    return classifications, reconstruction_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(original_data, reconstructed_data, threshold=0.5):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calcula o Erro Absoluto Médio (MAE) entre os dados originais e reconstruídos.\n",
    "\n",
    "    Args:\n",
    "    - original_data: array NumPy contendo os dados originais.\n",
    "    - reconstructed_data: array NumPy contendo os dados reconstruídos pelo modelo.\n",
    "\n",
    "    Returns:\n",
    "    - mae: o Erro Absoluto Médio entre os dados originais e reconstruídos.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Calcula a diferença absoluta entre os dados originais e reconstruídos\n",
    "    # Calcula o MAE como a média da diferença absoluta\n",
    "    mae = np.mean((np.abs(original_data - reconstructed_data)), axis=(1, 2))\n",
    "\n",
    "    classifications = np.where(mae < threshold, 1, -1)\n",
    "\n",
    "    del mae\n",
    "\n",
    "    return classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold_mse(original_data, predicted_data, proportion, threshold=0.5):\n",
    "\n",
    "    reconstruction_errors = np.mean(np.square(original_data - predicted_data), axis=(1, 2))\n",
    "\n",
    "    classifications = np.where(reconstruction_errors < threshold, 1, -1)\n",
    "\n",
    "    del reconstruction_errors\n",
    "\n",
    "    proportion_predicted = len(classifications[classifications == -1]) / len(classifications)\n",
    "\n",
    "    del classifications\n",
    "\n",
    "    print(f\"Threshold: {threshold}, Proportion_predicted: {proportion_predicted}\")\n",
    "\n",
    "    if proportion_predicted < proportion:\n",
    "        del proportion_predicted\n",
    "        return find_best_threshold_mse(original_data, predicted_data, proportion, 0.9*threshold)\n",
    "    elif proportion_predicted > proportion:\n",
    "        del proportion_predicted\n",
    "        return find_best_threshold_mse(original_data, predicted_data, proportion, 1.1*threshold)\n",
    "    else:\n",
    "        del proportion_predicted\n",
    "        return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold(y_true, y_scores):\n",
    "    \"\"\"\n",
    "    Encontra o melhor threshold baseado na proporção correta entre dados malignos e benignos.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (np.array): Array de valores verdadeiros (-1 para benigno, 1 para maligno)\n",
    "    y_scores (np.array): Array de scores preditos pelo modelo\n",
    "\n",
    "    Returns:\n",
    "    float: Melhor threshold encontrado\n",
    "    \"\"\"\n",
    "    \n",
    "    # Certificar que os inputs são arrays numpy\n",
    "    y_true = np.array(y_true)\n",
    "    y_scores = np.array(y_scores)\n",
    "    \n",
    "    # Ordenar os scores e calcular possíveis thresholds\n",
    "    thresholds = np.sort(y_scores)\n",
    "    \n",
    "    # Inicializar variáveis para acompanhar o melhor threshold e melhor acurácia ponderada\n",
    "    best_threshold = None\n",
    "    best_weighted_accuracy = -np.inf\n",
    "    \n",
    "    # Calcular proporção dos dados malignos e benignos\n",
    "    prop_malignos = np.sum(y_true == 1) / len(y_true)\n",
    "    prop_benignos = np.sum(y_true == -1) / len(y_true)\n",
    "    \n",
    "    for threshold in tqdm(thresholds):\n",
    "        # Calcular predições baseadas no threshold atual\n",
    "        y_pred = np.where(y_scores >= threshold, 1, -1)\n",
    "        \n",
    "        # Calcular acurácia ponderada\n",
    "        accuracy_malignos = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_true == 1)\n",
    "        accuracy_benignos = np.sum((y_true == -1) & (y_pred == -1)) / np.sum(y_true == -1)\n",
    "        \n",
    "        weighted_accuracy = prop_malignos * accuracy_malignos + prop_benignos * accuracy_benignos\n",
    "        \n",
    "        # Atualizar melhor threshold se a acurácia ponderada atual for melhor\n",
    "        if weighted_accuracy > best_weighted_accuracy:\n",
    "            best_weighted_accuracy = weighted_accuracy\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Registrando os erros de reconstrução:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_mse, reconstruction_errors = mean_square_error(test_data_2, predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontrando um bom Threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = find_best_threshold(test_data_2_labels, reconstruction_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificando de acordo com o Threshold encontrado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_mse, reconstruction_errors = mean_square_error(test_data_2, predicts, THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classifications_mse[classifications_mse == -1]) / len(classifications_mse), malicious_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_errors_rounded = np.where(reconstruction_errors > THRESHOLD, -1, 1)\n",
    "reconstruction_errors_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, y_score, max_fpr=1.0):\n",
    "  fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "  aucroc = roc_auc_score(y_true, y_score)\n",
    "  plt.plot(100*fpr[fpr < max_fpr], 100*tpr[fpr < max_fpr], label=f'ROC Curve (AUC = {aucroc:.4f})')\n",
    "  plt.xlim(-2,102)\n",
    "  plt.xlabel('FPR (%)')\n",
    "  plt.ylabel('TPR (%)')\n",
    "  plt.legend()\n",
    "  plt.title('ROC Curve and AUCROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curva ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(test_data_2_labels, 1/reconstruction_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(y_true, y_score):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "    plt.plot(recall, precision, marker='.')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curva Recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_curve(test_data_2_labels, 1/reconstruction_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "  cm = confusion_matrix(y_true, y_pred)\n",
    "  group_counts = [f'{value:.0f}' for value in confusion_matrix(y_true, y_pred).ravel()]\n",
    "  group_percentages = [f'{value*100:.2f}%' for value in confusion_matrix(y_true, y_pred).ravel()/np.sum(cm)]\n",
    "  labels = [f'{v1}\\n{v2}' for v1, v2 in zip(group_counts, group_percentages)]\n",
    "  labels = np.array(labels).reshape(2,2)\n",
    "  sns.heatmap(cm, annot=labels, cmap='Oranges', xticklabels=['Predicted Benign', 'Predicted Malicious'], yticklabels=['Actual Benign', 'Actual Malicious'], fmt='')\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de Confusão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_data_2_labels, reconstruction_errors_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overall_metrics(y_true, y_pred):\n",
    "  tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "  acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "  tpr = tp/(tp+fn)\n",
    "  fpr = fp/(fp+tn)\n",
    "  precision = tp/(tp+fp)\n",
    "  f1 = (2*tpr*precision)/(tpr+precision)\n",
    "  return {'acc':acc,'tpr':tpr,'fpr':fpr,'precision':precision,'f1-score':f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas Gerais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_overall_metrics(test_data_2_labels, reconstruction_errors_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando modelo com diferentes bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = str(THRESHOLD).replace(\".\",\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'models/model_LSTM_{s_OR_ns}_{classifier_type}_ws{WINDOW_SIZE}_t{THRESHOLD}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'models/model_LSTM_{s_OR_ns}_{classifier_type}_ws{WINDOW_SIZE}_t{THRESHOLD}.pkl', 'wb') as arquivo:\n",
    "    pickle.dump(model, arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model, f\"models/model_LSTM_{s_OR_ns}_{classifier_type}_ws{WINDOW_SIZE}_t{THRESHOLD}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(scaler, f\"models/scalers/scaler_model_LSTM_{s_OR_ns}_{classifier_type}_ws{WINDOW_SIZE}_t{THRESHOLD}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
